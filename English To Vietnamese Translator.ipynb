{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6a39ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92188de9",
   "metadata": {},
   "source": [
    "## MNT Model to convert English sentences to Vietnamese."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000ff97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting Datasets\n",
    "!curl -O -J https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/train.en\n",
    "!curl -O -J https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/train.vi\n",
    "\n",
    "!curl -O -J https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/vocab.en\n",
    "!curl -O -J https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/vocab.vi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45c5b6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sentences = 100000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958032c3",
   "metadata": {},
   "source": [
    "### Getting Engish Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35cd44e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_sentences = []\n",
    "\n",
    "with open('./train.en', 'r', encoding='utf-8') as file:\n",
    "    for i, each_line in enumerate(file):\n",
    "        \n",
    "        if i < 50:\n",
    "            continue\n",
    "            \n",
    "        if i == max_sentences + 50:\n",
    "            break\n",
    "        \n",
    "        sentence_split_by_spaces = each_line.strip()\n",
    "        en_sentences.append(sentence_split_by_spaces)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3492f95e",
   "metadata": {},
   "source": [
    "### Getting Vietnamese Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ea68a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "vi_sentences = []\n",
    "\n",
    "with open('./train.vi', 'r', encoding='utf-8') as file:\n",
    "    for i, each_line in enumerate(file):\n",
    "        \n",
    "        if i < 50:\n",
    "            continue\n",
    "            \n",
    "        if i == max_sentences + 50:\n",
    "            break\n",
    "        \n",
    "        sentence_split_by_spaces = each_line.strip()\n",
    "        vi_sentences.append(sentence_split_by_spaces)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a3ef5b",
   "metadata": {},
   "source": [
    "### Insertings tags on the start & end of each sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8fb159f",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_sentences = ['<s> ' + sentence.strip() + ' </s>' for sentence in en_sentences]\n",
    "\n",
    "vi_sentences = ['<s> ' + sentence.strip() + ' </s>' for sentence in vi_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda4dd51",
   "metadata": {},
   "source": [
    "### Getting samples of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de314da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> In each one of those assessments that we write , we always tag on a summary , and the summary is written for a non-scientific audience . </s>\n",
      "->\n",
      "<s> Trong mỗi bản đánh giá chúng tôi viết , chúng tôi luôn đính kèm một bản tóm lược , được viết cho những độc giả không chuyên về khoa học . </s>\n",
      "\n",
      "\n",
      "\n",
      "<s> And we hand that summary to journalists and policy makers , in order to make headlines like these . </s>\n",
      "->\n",
      "<s> Chúng tôi đưa bản tóm lược cho các nhà báo và nhà chính sách để có được những dòng tít như thế này . </s>\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for en, vi in zip(en_sentences[:2], vi_sentences[:2]):\n",
    "    print(en)\n",
    "    print(\"->\")\n",
    "    print(vi)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70404726",
   "metadata": {},
   "source": [
    "### Splitting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07b7190f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "432397b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_en_sentences, valid_test_en_sentences, train_vi_sentences, valid_test_vi_sentences = train_test_split(en_sentences, \n",
    "                                                                                                            vi_sentences,\n",
    "                                                                                                            test_size=0.2,\n",
    "                                                                                                            shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fe797c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_en_sentences, test_en_sentences, valid_vi_sentences, test_vi_sentences = train_test_split(valid_test_en_sentences,\n",
    "                                                                                               valid_test_vi_sentences,\n",
    "                                                                                               test_size=0.5,\n",
    "                                                                                               shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58b1b5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Train set: 80000\n",
      "Shape of Valid set: 10000\n",
      "Shape of Test set: 10000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of Train set: {len(train_en_sentences)}\")\n",
    "print(f\"Shape of Valid set: {len(valid_en_sentences)}\")\n",
    "print(f\"Shape of Test set: {len(test_en_sentences)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bddcf2d",
   "metadata": {},
   "source": [
    "### Getting statistics on How long each sentences are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3568b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths of English Sentences:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    80000.000000\n",
       "mean        22.187625\n",
       "std         14.734221\n",
       "min          3.000000\n",
       "50%         18.000000\n",
       "75%         28.000000\n",
       "95%         49.000000\n",
       "max        630.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Lengths of English Sentences:\")\n",
    "pd.Series(train_en_sentences).str.split(\" \").apply(len).describe(percentiles=[0.5, 0.75, 0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac835f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_en_seq = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d87e161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths of Vietnamese Sentences:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    80000.000000\n",
       "mean        26.885437\n",
       "std         18.675991\n",
       "min          3.000000\n",
       "50%         22.000000\n",
       "75%         34.000000\n",
       "95%         61.000000\n",
       "max        852.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Lengths of Vietnamese Sentences:\")\n",
    "pd.Series(train_vi_sentences).str.split(\" \").apply(len).describe(percentiles=[0.5, 0.75, 0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26fe55e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vi_seq = 61"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82fe7fa",
   "metadata": {},
   "source": [
    "### Finding Unique number of Vocabs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61fdaad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocab:\n",
      "Samples of English words: ['<s>', '</s>', 'Rachel', ':', 'The', 'science', 'behind', 'a', 'climate', 'headline']\n",
      "Size of Engish vocab 17190\n"
     ]
    }
   ],
   "source": [
    "print(\"English Vocab:\")\n",
    "\n",
    "en_vocab = []\n",
    "\n",
    "with open(\"./vocab.en\", \"r\", encoding='utf-8') as file:\n",
    "    for i, each_word in enumerate(file):\n",
    "        \n",
    "        # Removing of the unk token\n",
    "        if i == 0:\n",
    "            continue\n",
    "        \n",
    "        en_vocab.append(each_word.strip())\n",
    "\n",
    "        \n",
    "n_en_vocab = len(en_vocab)\n",
    "print(f\"Samples of English words: {en_vocab[:10]}\")\n",
    "print(f\"Size of Engish vocab {n_en_vocab}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "342b192e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vietnamese Vocab:\n",
      "Samples of Vietnamese words: ['<s>', '</s>', 'Khoa', 'học', 'đằng', 'sau', 'một', 'tiêu', 'đề', 'về']\n",
      "Size of Vietnamese vocab 7708\n"
     ]
    }
   ],
   "source": [
    "print(\"Vietnamese Vocab:\")\n",
    "\n",
    "vi_vocab = []\n",
    "\n",
    "with open(\"./vocab.vi\", \"r\", encoding='utf-8') as file:\n",
    "    for i, each_word in enumerate(file):\n",
    "        \n",
    "        # Removing of the unk token\n",
    "        if i == 0:\n",
    "            continue\n",
    "        \n",
    "        vi_vocab.append(each_word.strip())\n",
    "\n",
    "n_vi_vocab = len(vi_vocab)\n",
    "print(f\"Samples of Vietnamese words: {vi_vocab[:10]}\")\n",
    "print(f\"Size of Vietnamese vocab {n_vi_vocab}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800d798f",
   "metadata": {},
   "source": [
    "### Training TextVectorizer Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "192b961f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-08 22:15:00.645891: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-01-08 22:15:00.646133: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-08 22:15:00.904516: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-01-08 22:15:00.932679: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "encoder_text_vectorizer = layers.TextVectorization(max_tokens=n_en_vocab,\n",
    "                                                  standardize=None,\n",
    "                                                  split='whitespace',\n",
    "                                                  output_sequence_length=n_en_seq,\n",
    "                                                  name=\"encoder_text_vectorizer_layer\")\n",
    "## Needs to be a numPy array \n",
    "tmp = np.array(train_en_sentences)\n",
    "\n",
    "encoder_text_vectorizer.adapt(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9836f04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Form of \"<s> This is a cat </s>\":\n",
      "\n",
      "[[   3   91   14   10 3706    4    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "\n",
      "Samples from layer: ['', '[UNK]', ',', '<s>', '</s>', '.', 'the', 'to', 'of', 'and', 'a', 'that', 'I', 'in', 'is', 'you', 'it', '&apos;s', 'we', 'And']\n"
     ]
    }
   ],
   "source": [
    "example = \"<s> This is a cat </s>\"\n",
    "\n",
    "print(f\"Tokenized Form of \\\"{example}\\\":\\n\\n{encoder_text_vectorizer([example])}\\n\")\n",
    "print(f\"Samples from layer: {encoder_text_vectorizer.get_vocabulary()[:20]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53415c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-08 22:16:21.217617: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "decoder_text_vectorizer = layers.TextVectorization(max_tokens=n_vi_vocab,\n",
    "                                                  standardize=None,\n",
    "                                                  split='whitespace',\n",
    "                                                  output_sequence_length=n_vi_seq - 1,\n",
    "                                                  name=\"decoder_text_vectorizer_layer\")\n",
    "## Needs to be a numPy array\n",
    "tmp = np.array(train_vi_sentences)\n",
    "\n",
    "decoder_text_vectorizer.adapt(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1534679c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Form of \"<s> Chúng tôi đưa bản tóm </s>\":\n",
      "\n",
      "[[   2   74    7  241  124 1525    3    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]]\n",
      "\n",
      "Samples from layer: ['', '[UNK]', '<s>', '</s>', ',', '.', 'là', 'tôi', 'một', 'có', 'và', 'những', 'chúng', 'của', 'ta', 'không', 'bạn', 'đó', 'người', 'trong']\n"
     ]
    }
   ],
   "source": [
    "example = \"<s> Chúng tôi đưa bản tóm </s>\"\n",
    "\n",
    "print(f\"Tokenized Form of \\\"{example}\\\":\\n\\n{decoder_text_vectorizer([example])}\\n\")\n",
    "print(f\"Samples from layer: {decoder_text_vectorizer.get_vocabulary()[:20]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09c0836",
   "metadata": {},
   "source": [
    "### Creating a simple seq2seq model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f2980a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Encoder\n",
    "encoder_input = layers.Input(shape=(1,) , dtype=tf.string, name=\"encoder_input\")\n",
    "\n",
    "x = encoder_text_vectorizer(encoder_input)\n",
    "x = layers.Embedding(input_dim=n_en_vocab, output_dim=256, mask_zero=True, name=\"encoder_embedding\")(x)\n",
    "x = layers.GRU(256, return_sequences=True, name=\"encoder_gru_1\")(x)\n",
    "\n",
    "encoder_gru_last_layer, encoder_gru_last_state = layers.GRU(256, return_sequences=True, return_state=True, name=\"encoder_gru_last\")(x)\n",
    "\n",
    "\n",
    "encoder_model = tf.keras.models.Model(inputs=encoder_input, outputs=encoder_gru_last_layer, name=\"encoder_model\")\n",
    "\n",
    "## Decoder\n",
    "decoder_input = layers.Input(shape=(1,), dtype=tf.string, name=\"decoder_input\")\n",
    "\n",
    "x = decoder_text_vectorizer(decoder_input)\n",
    "x = layers.Embedding(input_dim=n_vi_vocab, output_dim=256, mask_zero=True, name=\"decoder_embedding\")(x)\n",
    "x = layers.GRU(256, return_sequences=True, name=\"decoder_gru_1\")(x, initial_state=encoder_gru_last_state)\n",
    "x = layers.GRU(256, return_sequences=True, name=\"decoder_gru_last\")(x)\n",
    "\n",
    "decoder_out = layers.Dense(n_vi_vocab, activation='softmax')(x)\n",
    "\n",
    "\n",
    "seq2seq = tf.keras.models.Model(inputs=[encoder_model.inputs, decoder_input], outputs=decoder_out)\n",
    "seq2seq.compile(optimizer='adam', loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf27df24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_input (InputLayer)     [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " encoder_text_vectorizer_layer   (None, 50)          0           ['encoder_input[0][0]']          \n",
      " (TextVectorization)                                                                              \n",
      "                                                                                                  \n",
      " decoder_input (InputLayer)     [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " encoder_embedding (Embedding)  (None, 50, 256)      4400640     ['encoder_text_vectorizer_layer[1\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " decoder_text_vectorizer_layer   (None, 60)          0           ['decoder_input[0][0]']          \n",
      " (TextVectorization)                                                                              \n",
      "                                                                                                  \n",
      " encoder_gru_1 (GRU)            (None, 50, 256)      394752      ['encoder_embedding[0][0]']      \n",
      "                                                                                                  \n",
      " decoder_embedding (Embedding)  (None, 60, 256)      1973248     ['decoder_text_vectorizer_layer[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " encoder_gru_last (GRU)         [(None, 50, 256),    394752      ['encoder_gru_1[0][0]']          \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " decoder_gru_1 (GRU)            (None, 60, 256)      394752      ['decoder_embedding[0][0]',      \n",
      "                                                                  'encoder_gru_last[0][1]']       \n",
      "                                                                                                  \n",
      " decoder_gru_last (GRU)         (None, 60, 256)      394752      ['decoder_gru_1[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 60, 7708)     1980956     ['decoder_gru_last[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 9,933,852\n",
      "Trainable params: 9,933,852\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seq2seq.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f449480",
   "metadata": {},
   "source": [
    "### Preparing data for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bf3df5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(X, y, tensor=False, batch_size=128):\n",
    "    \n",
    "    encoder_input =  np.array( X )\n",
    "    decoder_input = np.array( [\" \".join(sentence.split(\" \")[:-1]) for sentence in y] )\n",
    "    \n",
    "    decoder_labels = [\" \".join(sentence.split(\" \")[1:]) for sentence in y]\n",
    "    decoder_labels = decoder_text_vectorizer(decoder_labels).numpy()\n",
    "    \n",
    "    if tensor:\n",
    "        encoder_input = tf.data.Dataset.from_tensor_slices(encoder_input)\n",
    "        decoder_input = tf.data.Dataset.from_tensor_slices(decoder_input)\n",
    "        decoder_labels = tf.data.Dataset.from_tensor_slices(decoder_labels)\n",
    "        \n",
    "        inputs = tf.data.Dataset.zip( (encoder_input, decoder_input) )\n",
    "        labels = tf.data.Dataset.zip( (inputs, decoder_labels) ).batch(batch_size=batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "        \n",
    "        return labels, None\n",
    "    \n",
    "    return (encoder_input, decoder_input), decoder_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c927d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "add136f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels = prepare_data(train_en_sentences, train_vi_sentences, tensor=True)\n",
    "valid_features, valid_labels = prepare_data(valid_en_sentences, valid_vi_sentences, tensor=True)\n",
    "test_features, test_labels = prepare_data(test_en_sentences, test_vi_sentences, tensor=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64a77a2",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2fb65def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-08 22:23:46.351360: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-08 22:23:47.094698: W tensorflow/core/common_runtime/forward_type_inference.cc:231] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT8\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\twhile inferring type of node 'cond_41/output/_22'\n",
      "2023-01-08 22:23:47.097859: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-08 22:23:47.407293: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-08 22:23:47.587526: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-08 22:23:47.785700: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-08 22:23:48.171875: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-08 22:23:48.450840: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-08 22:23:48.689871: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-08 22:23:48.920663: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - ETA: 0s - loss: 2.6159 - accuracy: 0.0507"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-08 22:26:17.688570: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-08 22:26:18.121824: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-08 22:26:18.271242: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-08 22:26:18.416332: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-08 22:26:18.582482: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 163s 251ms/step - loss: 2.6159 - accuracy: 0.0507 - val_loss: 2.5642 - val_accuracy: 0.0534\n",
      "Epoch 2/2\n",
      "625/625 [==============================] - 152s 243ms/step - loss: 2.5331 - accuracy: 0.0748 - val_loss: 2.4331 - val_accuracy: 0.1078\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "\n",
    "history = seq2seq.fit(train_features,\n",
    "                      epochs=epochs, \n",
    "                      batch_size=batch_size,\n",
    "                     validation_batch_size=batch_size,\n",
    "                     validation_data=valid_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e84732e",
   "metadata": {},
   "source": [
    "### Inference Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f3cfeb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Encoder\n",
    "encoder_input = layers.Input(shape=(1,) , dtype=tf.string, name=\"encoder_input\")\n",
    "\n",
    "x = seq2seq.get_layer(\"encoder_text_vectorizer_layer\")(encoder_input)\n",
    "x = seq2seq.get_layer(\"encoder_embedding\")(x)\n",
    "x = seq2seq.get_layer(\"encoder_gru_1\")(x)\n",
    "\n",
    "encoder_gru_last_layer, encoder_gru_last_state = seq2seq.get_layer(\"encoder_gru_last\")(x)\n",
    "\n",
    "\n",
    "encoder_model = tf.keras.models.Model(inputs=encoder_input, outputs=[encoder_gru_last_layer, encoder_gru_last_state], name=\"encoder_model\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Decoder\n",
    "decoder_input = layers.Input(shape=(1,), dtype=tf.string, name=\"decoder_input\")\n",
    "decoder_encoder_state = layers.Input(shape=(256,))\n",
    "\n",
    "x = seq2seq.get_layer(\"decoder_text_vectorizer_layer\")(decoder_input)\n",
    "x = seq2seq.get_layer(\"decoder_embedding\")(x)\n",
    "\n",
    "gru_1 = layers.GRU(256, return_sequences=True, name=\"decoder_gru_1\")\n",
    "x = gru_1(x, initial_state=decoder_encoder_state)\n",
    "\n",
    "decoder_gru_last_layer = layers.GRU(256, return_sequences=True, name=\"decoder_gru_last\")\n",
    "gru_out = decoder_gru_last_layer(x)\n",
    "\n",
    "decoder_out = seq2seq.get_layer(\"dense_1\")(gru_out)\n",
    "\n",
    "\n",
    "inference_model = tf.keras.models.Model(inputs=[decoder_input, decoder_encoder_state], outputs=[decoder_out, gru_out])\n",
    "inference_model.compile()\n",
    "\n",
    "gru_1.set_weights(seq2seq.get_layer(\"decoder_gru_1\").get_weights())\n",
    "decoder_gru_last_layer.set_weights(seq2seq.get_layer(\"decoder_gru_last\").get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9a1ceafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " decoder_input (InputLayer)     [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " decoder_text_vectorizer_layer   (None, 60)          0           ['decoder_input[0][0]']          \n",
      " (TextVectorization)                                                                              \n",
      "                                                                                                  \n",
      " decoder_embedding (Embedding)  (None, 60, 256)      1973248     ['decoder_text_vectorizer_layer[5\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)           [(None, 256)]        0           []                               \n",
      "                                                                                                  \n",
      " decoder_gru_1 (GRU)            (None, 60, 256)      394752      ['decoder_embedding[5][0]',      \n",
      "                                                                  'input_5[0][0]']                \n",
      "                                                                                                  \n",
      " decoder_gru_last (GRU)         (None, 60, 256)      394752      ['decoder_gru_1[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 60, 7708)     1980956     ['decoder_gru_last[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,743,708\n",
      "Trainable params: 4,743,708\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inference_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0c261da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_ids_to_word = {key:value for key, value in enumerate(decoder_text_vectorizer.get_vocabulary())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2a794b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_translation(english_text):\n",
    "    \n",
    "    #Generate content vector\n",
    "    encoder_gru_last_layer, content_vector = encoder_model( np.array(english_text) )\n",
    "    \n",
    "    #y_pred. Starting value <s>\n",
    "    y_pred = np.array([[\"<s>\"]])\n",
    "    predicted_sentence = []\n",
    "    \n",
    "    for _ in range(100):\n",
    "        \n",
    "        if y_pred[0][0] == '</s>':\n",
    "            break\n",
    "            \n",
    "        softmax_probability, content_vector = inference_model.predict([y_pred, content_vector], verbose=0)\n",
    "        # why\n",
    "        content_vector = content_vector[:, 0, :]\n",
    "        # Perform argmax on the last axis & get the highest value\n",
    "        softmax_prediction = np.argmax(softmax_probability, axis=-1).ravel()[0]\n",
    "        y_pred = np.array([[word_ids_to_word[softmax_prediction]]])\n",
    "        \n",
    "        predicted_sentence.append( word_ids_to_word[softmax_prediction] )\n",
    "    \n",
    "    return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "013bf66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Và']\n",
      "['Và', 'Và']\n",
      "['Và', 'Và', 'ta']\n",
      "['Và', 'Và', 'ta', 'Và']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và']\n",
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Và', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và', 'ta', 'Và']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Và',\n",
       " 'Và',\n",
       " 'ta',\n",
       " 'Và',\n",
       " 'ta',\n",
       " 'Và',\n",
       " 'ta',\n",
       " 'Và',\n",
       " 'ta',\n",
       " 'Và',\n",
       " 'ta',\n",
       " 'Và',\n",
       " 'ta',\n",
       " 'Và',\n",
       " 'ta',\n",
       " 'Và',\n",
       " 'ta',\n",
       " 'Và',\n",
       " 'ta',\n",
       " 'Và',\n",
       " 'ta',\n",
       " 'Và',\n",
       " 'ta',\n",
       " 'Và',\n",
       " 'ta',\n",
       " 'Và',\n",
       " 'ta',\n",
       " 'Và',\n",
       " 'ta',\n",
       " 'Và',\n",
       " 'ta',\n",
       " 'Và',\n",
       " 'ta',\n",
       " 'Và',\n",
       " 'ta',\n",
       " 'Và',\n",
       " 'ta',\n",
       " 'Và',\n",
       " 'ta',\n",
       " 'Và',\n",
       " 'ta',\n",
       " 'Và',\n",
       " 'ta',\n",
       " 'Và',\n",
       " 'ta',\n",
       " 'Và',\n",
       " 'ta',\n",
       " 'Và',\n",
       " 'ta',\n",
       " 'Và',\n",
       " 'ta',\n",
       " 'Và',\n",
       " 'ta',\n",
       " 'Và',\n",
       " 'ta',\n",
       " 'Và',\n",
       " 'ta',\n",
       " 'Và',\n",
       " 'ta',\n",
       " 'Và',\n",
       " 'ta',\n",
       " 'Và',\n",
       " 'ta',\n",
       " 'Và',\n",
       " 'ta',\n",
       " 'Và',\n",
       " 'ta',\n",
       " 'Và',\n",
       " 'ta',\n",
       " 'Và',\n",
       " 'ta',\n",
       " 'Và',\n",
       " 'ta',\n",
       " 'Và',\n",
       " 'ta',\n",
       " 'Và',\n",
       " 'ta',\n",
       " 'Và',\n",
       " 'ta',\n",
       " 'Và',\n",
       " 'ta',\n",
       " 'Và',\n",
       " 'ta',\n",
       " 'Và',\n",
       " 'ta',\n",
       " 'Và',\n",
       " 'ta',\n",
       " 'Và',\n",
       " 'ta',\n",
       " 'Và',\n",
       " 'ta',\n",
       " 'Và',\n",
       " 'ta',\n",
       " 'Và',\n",
       " 'ta',\n",
       " 'Và',\n",
       " 'ta',\n",
       " 'Và',\n",
       " 'ta',\n",
       " 'Và']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_translation([\"Hello world\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11771f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow 2.9)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
